---
title: "Coho Forecast Time Scales"
author: "TC Wainwright"
date: 'Updated: `r Sys.Date()`'
output:
  html_document:
    fig_caption: yes
    highlight: tango
    self_contained: no
    theme: journal
  pdf_document:
    fig_caption: yes
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.height=4, fig.width=6, warning=TRUE)
## load(".RData") #not done automatically in interactive knitr session.
```

**NOTE**: This is an R Markdown document. Markdown is a simple formatting 
syntax for authoring HTML, PDF, and MS Word documents. For more details on 
using R Markdown see <http://rmarkdown.rstudio.com>.

Besides R base and recommended packages, this document requires R packages 
`akima` and `RColorBrewer`.

## Introduction

This document details the analyses in Wainwright (2019, [ADD TITLE], Progr. 
Oceanogr. XX:XXX-XXX).

## Data

### Update the data set

Update the environmental data sets, if desired (set the following flag to 
``TRUE``).

```{r UpdateFlag}
UPDATE.DATA <- FALSE
```
This only needs to be done if the file "AnalysisData.csv" is out-of-date.

Monthly environmental series are restructured to 4 seasons (Win [JFM], 
Spr [AMJ], Sum [JAS], and Aut [OND]). Annual environmental series are left as 
is. Coho salmon recruits and parental spanwer abundance are lagged to match the 
environment during ocean entry, so no need to lag within the analysis.

**Warning**: Updating data is error-prone, as URLs and file formats change 
frequently. Check output for warnings and errors and correct the UpdateData and 
ProcessData scripts as needed before finalizing the analysis.

**Note**: Biological data (salmon population and "stoplight" datasets) and 
Loggerwell Spring Transition (SpringTrans.csv)  must be updated by hand, and 
files put in the "Data/HandEdit" folder! Water temperature historical data 
(WT.OIMB.\*) files should never change, but must be present.

```{r UpdateData}
if (UPDATE.DATA) { 
  options(warn=1)  # Print all messages
  
  olddir <- setwd('R-scripts') # Move into scripts directory
  print(getwd())
  list.files()
  
  d.dir <- file.path('..', 'Data') # Data directory
  dd.dir <- file.path(d.dir, 'Download') # Downloaded data directory
  hand.dir <- file.path(d.dir, 'HandEdit') # Hand-edit data directory

  cat('\nUpdating source datasets.\n')
  source('UpdateData.R', echo=F)
  
  cat('\nComputing derived datasets.\n')
  source('ProcessData.R', echo=F)
  
  cat('\nWriting final analysis file.\n')
  source('ConsolidateData.R', echo=F)
  
  setwd(olddir) # Restore working directory
} else {
  cat("NO UPDATES REQUESTED.")
}
```

Read in the full data set, and do a plot so we can double check the alignment 
of salmon data against published data sets.

```{r ReadData, fig.height=6, fig.width=9}
# Environmental data:
analdata <- read.csv(file.path("Data", "AnalysisData.csv"), header=TRUE)
# shorten NPGO abbrev. to 3 letters:
names(analdata) <- sub('NPGO.', 'NPG.', names(analdata))
analdata <- analdata[!is.na(analdata$OCN.RCR), ] # Use only years with recruits.
# Plot to check data alignment
with(analdata, {
  plot(YEAR, scale(OCN.RCR), type='l', ylim=c(-3,3), tck=1, 
       xlab='Year', ylab='Scaled Value');
  lines(YEAR, scale(OCN.SPN), col=2);
  lines(YEAR, scale(PDO.AMJ), col=3);
  lines(YEAR, scale(OPIH.RC), col=1, lty=2);
  lines(YEAR, scale(OPIH.SM), col=2, lty=2)
  })
legend('bottom', c('OCN.RCR','OCN.SPN','PDO.AMJ','OPIH.RC','OPIH.SM'), 
       col=c(1,2,3,1,2), lty=c(1,1,1,2,2), horiz=TRUE)
```

Yes, the data line up properly. The 2011 and 2014 peaks in OCN recruits and 
spawners are plotted in ocean entry years 2010 and 2013 for recruits returning 
1 year later, and in years 2013 and 2016 for spawners that entered ocean at 
age 2. 2009 and 2014 peaks in OPIH recruits are correctly plotted one year 
earlier, and OPIH smolt local peaks in 2007-08 and 2000 are correct.

###Select predictors

Change sign of NPGO, NPI & UWI so they correlate positively with other 
varialbles.

```{r SelectPredictors}
predictors <- analdata[ , -(1:5)]  # Whole data set except Year and coho data
## reverse sign on some predictors to have consistent +/- regr. slopes
predictors[ , grep('NPG.', colnames(predictors))] <- 
  - predictors[ , grep('NPG.', colnames(predictors))]
predictors[ , grep('UWI.', colnames(predictors))] <- 
  - predictors[ , grep('UWI.', colnames(predictors))]
plot.names <- colnames(predictors)   # FUTURE: Pretty names
## Testing - subset of predictors 
## predictors <- predictors[ , 1:12]
```

## Analysis

### Function definitions

First, a function to compute the leave-one-out cv skill score for a bivariate 
linear model, defined as:
$$
1 - \frac { (n-1) \sum (\hat Y_{(i)} - Y_i)^2 } { (n-2) \sum (\bar Y - Y_i)^2}
$$
where the sums are over the $n$ data points and $\hat Y_{(i)}$ is the predicted 
value of $Y_i$ from the model with point $i$ left out.

Crude, but works. Should be able to do this more efficiently for a linear model.

```{r LOOFunc}
loo.skill <- compiler::cmpfun(function(df) {
  # Leave-one-out cross-validation, scaled to skill score, for a 
  #   bivariate linear regr.
  # df is a dataframe with two columns: X & Y
  ## check for sufficient data (non-NAs for X & Y in at least 5 cases)
  if (sum(!is.na(df$X+df$Y)) > 4) { # OK
    ybar <- mean(df$Y)
    n <- nrow(df)
    loo.pred <- function(i) predict(lm(Y ~ X, data=df[-i,]), newdata=df[i,])
    .pred <- sapply(1:n, loo.pred)
    loo.cvs <- 1 - (n-1) / (n-2) * sum((.pred - df$Y)^2) / sum((ybar - df$Y)^2)
    return(list(CVS=loo.cvs, X=df$X, Y=df$Y, Pred=.pred))
  } else { # Insuffient data
    return(list(CVS=NA, X=df$X, Y=df$Y, Pred=NULL))
  } # if (sum...)
}) # loo.skill
```

Next, a function to compute the model fit at all scales. For a multivariate 
data time series of length N, applies a goodness-of-fit function to all 
overlapping subseries of length n, where n runs from a lower limit k (10 by 
default) to the entire series length. Results are stored in an N x (N-k+1) 
matrix suitable for plotting via ``image``.

```{r tsapplyFunc}
tsapply <- compiler::cmpfun(function(dataser, goffnc, minlen=10) {
  # dataser is a multivariate time series, in the form of a data.frame
  # goffnc is a function that fits a model to a data frame, and returns 
  #   a single numeric goodness-of-fit measure.
  # minlen is the minumum data subset length
  N <- nrow(dataser)
  res <- data.frame(time=NULL, scale=NULL, gof=NULL)
  for (n in minlen:N) {
    for (j in 1:(N-n+1)) {
      .sub <- j + 0:(n-1)
      if (length(.sub) != n) stop("length(.sub) = ", length(.sub), ", n = ", n)
      .dat <- dataser[.sub, ]
      res <- rbind(res, data.frame(time=max(.sub), scale=n, gof=goffnc(.dat)))
    } # for(t)
  } # for(n)
  return(res)
}) # tsapply
```

We want a graphic that shows both the strength of the relationship (skill) and 
its direction (sign of the slope), so define a "signed skill" metric by 
truncating the skill measure to be non-negative (negative skill means really 
bad relationship anyway), then multiplying by the sign of the regression slope.

```{r slopeSkill}
slpSkill <- function(X, Y) {
  #return LOO skill and regression slope in one data frame
  loo.res <- tsapply(data.frame(X=X,Y=Y), function(df) {loo.skill(df)$CVS})
  # get regression slopes for color-coding graph
  slp.res <- tsapply(data.frame(X=X,Y=Y), function(df) {
    if (sum(!is.na(df$X+df$Y)) > 4) { # OK
      return(coefficients(lm(Y ~ X, data=df))['X'])
    } else {
      return(NA)
    } # if(sum...)
  } # function(df)
  ) # tsapply()
  loo.res$slp <- slp.res$gof
  return(loo.res)
} # slpSkill()
```

Also make a function to plot the resulting metric as a function of time and 
scale. In the plot, color indicates sign (blue positive, red negative) and 
circle size indicates skill. Contours are added at skill levels 0.25 (thin 
dotted), 0.5 (dashed) and 0.75 (solid).

```{r skillPlot}
skillPlot <- function(ss, title="", dot.scale=0.5, add.contours=FALSE, ...) {
  # Plot signed skill on scale v time axis
  ss <- ss[!is.na(ss$gof), ]      # remove na's for interp()
  ss$gof <- pmax(0,ss$gof) # get rid of negative values (very bad fit)
  plot(ss$time, ss$scale, type='n', asp=1.0, xaxs='r', 
       xlab='Interval Endpoint', ylab='Interval Length', ...)
  pl.lims <- par('usr') # get X & Y plot limits (Xmin,Xmax,Ymin,Ymax)
  xrange <- pl.lims[2] - pl.lims[1]
  yrange <- pl.lims[4] - pl.lims[3]
#  text(min(ss$time), max(ss$scale), title, cex=1.25, adj=c(0, 1), col='black')
  text(pl.lims[1]+0.05*xrange, pl.lims[4]-0.05*yrange, title, 
       cex=1.2, adj=c(0, 1), col='black')
#  text(min(ss$time), max(ss$scale) - 0.1 * diff(range(ss$scale)),
  text(pl.lims[1]+0.05*xrange, pl.lims[4]-0.1*yrange,
       paste0("Long-term Skill: ", round(ss$gof[ss$scale==max(ss$scale)],2)), 
       cex=1, adj=c(0,1), col='black')
#  text(min(ss$time), max(ss$scale) - 0.17 * diff(range(ss$scale)),
  text(pl.lims[1]+0.05*xrange, pl.lims[4]-0.15*yrange,
       paste0("Maximum Skill: ", round(max(ss$gof),2)), 
       cex=1, adj=c(0,1), col='black')
  symbols(ss$time, ss$scale,
            circles=dot.scale * sqrt(ss$gof), inches=FALSE, fg='grey80',
            bg=ifelse(ss$slp<0,"#D34364","#4364D3"), add=T)
  if (add.contours) {
    zz <- with(ss, akima::interp(time, scale, gof, xo=sort(unique(time)), 
                                 yo=sort(unique(scale))))
    contour(zz, levels=c(0.5, 0.75), 
          lty=c(1, 1), lwd=c(1, 2), col='black', 
          drawlabels=FALSE, add=TRUE)
  } # if(add.contours)
} # skillPlot()
```

Test skillPlot():

```{r tstSkillPlot, fig.height=6, fig.width=6}
X <- rnorm(20)
Y <- X + rnorm(20)
tst <- slpSkill(X, Y)
skillPlot(tst, title='Test', add.contours = TRUE)
rm(X, Y, tst)
```

## Real Data

Compute skill and sign of relationship for all years and scales across selected 
predictors. (This is quite compute-intensive, so run in parallel. Even so, only 
run if resulting output doesn't already exist, so to refresh results, delete 
``ss.out`` before running.)

```{r AnalLoop}
if (!exists("ss.out")) {
  preds <- as.list(names(predictors))
  names(preds) <- names(predictors)   # so result is a named list
  library(parallel)
  ## mc <- max(1, floor(detectCores()/2)) # use ca. half of available processors
  mc <- max(1, detectCores() - 1) # use all but one of available processors
  ss.out <- mclapply(preds, 
                     function (k) {
                       # log(OCNR Recruits)
                       ## x <- log(analdata$OCN.RCR)
                       # log(OCNR Recruits/Spawner)
                       ## x <- log(analdata$OCN.RCR / analdata$OCN.SPN)
                       # log(OPIH Recruits/Smolt)
                       #   NOTE: Recr in thousands, smolts in millions
                       x <- log(0.001 * analdata$OPIH.RC / analdata$OPIH.SM)
                       slpSkill(X=x, Y=predictors[ , k])
                     }
                     , mc.cores=mc)
  rm(mc, preds)
} # if (!exists(ss.out))
```

Summarize results and plot. Plots are done only for those with skill above 
a threshold. The X-axis is the year of ocean entry (return year - 1).

```{r Results, fig.height=6, fig.width=6}
skillthresh <- 0.00
op <- par(mfrow=c(2,2), mar=c(3,3,1,1), mgp=c(1.5,0.25,0), fg='grey', tck=1)
for (series in names(ss.out)) {
  cat('Predictor: ', series, '\n')
  ss <- ss.out[[series]]
  ss$time <- analdata$YEAR[ss$time]
  cat('\t Range of Skill: ', round(range(ss$gof, na.rm=TRUE),2), '\n')
##  if (max(ss$gof, na.rm=TRUE) > skillthresh) { 
    skillPlot(ss, title=series, dot.scale=1.0, xlim=c(1975,2015), ylim=c(10,50),
              add.contours = TRUE) 
##  } # if
} # for(series)
par(op)
rm(skillthresh, op)
```

## Selected Results for Manuscript

**TODO**: add function for dot-plots as in SurvivalAnalysis/SalmonClimatePred1.R.