---
title: "Ephemeral Relationships Project"
author: "Tom Wainwright, NOAA Northwest Fisheries Science Center"
date: 'Updated: `r Sys.Date()`'
output:
  html_document:
    fig_caption: yes
    highlight: tango
    self_contained: no
    theme: journal
  pdf_document:
    fig_caption: yes
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.height=4, fig.width=6, warning=TRUE)
## load(".RData") #not done automatically in interactive knitr session.
```

## Introduction

**NOTE:** This is an R Markdown document. Markdown is a simple formatting syntax for authoring 
HTML, PDF, and MS Word documents. For more details on using R Markdown see 
<http://rmarkdown.rstudio.com>.

## Data

Update the environmental data sets, if desired (edit value of "UPDATE.DATA"). 

**Warning**: Updating data is error-prone, as URLs and file formats change frequently. 
Check output for warnings and errors and correct the UpdateData and ProcessData scripts 
as needed before finalizing the analysis.

**Note**: Biological data (Coho populations and "stoplight" datasets) and Loggerwell Spring 
Transition (SpringTrans.csv)  must be updated by hand, and files put in the correct locations! 
Charleston water temperature historical data (WT.OIMB.*) files should never change, but must 
be present.

```{r UpdateData}
UPDATE.DATA <- TRUE
if (UPDATE.DATA) { 
  options(warn=1)  # Print all messages
  
  olddir <- setwd('R-scripts') # Move into scripts directory
  print(getwd())
  list.files()
  
  d.dir <- file.path('..', 'Data') # Data directory
  dd.dir <- file.path(d.dir, 'Download') # Downloaded data directory
  hand.dir <- file.path(d.dir, 'HandEdit') # Hand-edit data directory

  cat('\nUpdating source datasets.\n')
  source('UpdateData.R', echo=T)
  
  cat('\nComputing derived datasets.\n')
  source('ProcessData.R', echo=T)
  
  cat('\nWriting final analysis file.\n')
  source('ConsolidateData.R', echo=T)
  
  setwd(olddir) # Restore working directory
}
```

Read in the data. Environmental series are restructured to 4 seasons (Win [JFM], Spr [AMJ], Sum [JAS], & Aut [OND]) across all three years of the coho lifecycle: hatch year (year 0), ocean entry year (year 1), and return year (year 2). This eliminates series MEI, which was stored as 2-month averages instead of 3-month averages (no idea why) -- MEI was highly correlated with ONI anyway.

```{r ReadPhysData}
# Coho population data:
popdata <- read.table(file.path(hand.dir, "OCN_Rivers.dat"), header=TRUE)
popdata$logAD <- log(popdata$ADULTS)  # log-tranformed adults
# Shift popdata so year is hatch year (return year - 2)
popdata$YEAR <- popdata$YEAR - 2
# Filter out missing values
popdata <- popdata[!is.na(popdata$ADULTS), ]
# Environmental data:
envdata <- read.table(file.path(d.dir, "AnalysisData.csv"), header=TRUE)
# shorten NPGO abbrev. to 3 letters:
names(envdata) <- sub('NPGO_', 'NPG_', names(envdata))
# shorten season abbreviations for four seasons:
names(envdata) <- sub('_JFM', '_Wi', names(envdata))
names(envdata) <- sub('_AMJ', '_Sp', names(envdata))
names(envdata) <- sub('_JAS', '_Su', names(envdata))
names(envdata) <- sub('_OND', '_Fa', names(envdata))
##newdata <- cbind(YEAR=envdata$YEAR, SPR.TRN=envdata$SPR.TRN,
## No spring transition for now (messes up seasonal panel plots)
newdata <- cbind(YEAR=envdata$YEAR,
                 envdata[ , grep('_Wi', colnames(envdata))],
                 envdata[ , grep('_Sp', colnames(envdata))],
                 envdata[ , grep('_Su', colnames(envdata))],
                 envdata[ , grep('_Fa', colnames(envdata))])
lag0 <- newdata[1:(nrow(newdata)-2), ]
names(lag0) <- paste0(names(lag0), '_FW0') # Freshwater, year 0
lag1 <- newdata[2:(nrow(newdata)-1), ]
names(lag1) <- paste0(names(lag1), '_Oc1') # Ocean entry, year 1
lag2 <- newdata[3:(nrow(newdata)), ]
names(lag2) <- paste0(names(lag2), '_Oc2') # Ocean year 2, spawning
envdata <- cbind(YEAR=lag0$`YEAR_FW0`, lag0[ , -1], lag1[ , -1], lag2[ , -1])
envdata <- envdata[ , order(substr(names(envdata), 1, 3))]
rm(newdata, lag0, lag1, lag2)
# Make sure both data sets cover same set of years:
envdata <- envdata[envdata$YEAR %in% popdata$YEAR, ]
popdata <- popdata[popdata$YEAR %in% envdata$YEAR, ]
plot(popdata$YEAR, popdata$ADULTS, type='l', fg='grey', col='blue', 
     lwd=2, log='y',      xlab='Year', ylab='Abundance (1000\`s)', 
     main= 'OCNR Coho Adult Recruits')
```

Read in biological data. These are found in the NWFSC "Salmon Forecasting" website "Stoplight Chart". The data table is very messy with blank rows and text notes mixed in. Data series are rows, years are columns. First column is long data series names mixed with notes. Needs to be extracted row-by-row. First row is year and Biological indicators appear to be in rows 12-18. Variables are:

* CPR_Su - Copepod richness anom. (no. species; May-Sept)
* NCP_Su - N. copepod biomass anom. (mg C m-3; May-Sept)
* SCP_Su - S. copepod biomass anom. (mg C m-3; May-Sept)
* BioTrn - Biological transition(day of year)
* ICH_Wi - Ichthyoplankton biomass (mg C 1000 m-3; Jan-Mar)
* CHNjuv - Chinook salmon juvenile catches (no. km-1; June)
* COHjuv - Coho salmon juvenile catches (no. km-1; June)

**TODO:** These are read in, but not yet used in the analysis.

```{r ReadBiolData}
url <- "https://www.nwfsc.noaa.gov/research/divisions/fe/estuarine/oeip/documents/Table%20SF-03.csv"
bioraw <- read.csv(url, skip=1, header=FALSE)
## print(bioraw[,1]) #check row labels - make sure row numbers below are OK
biodata <- data.frame(t(bioraw[c(1, 12:18),2:ncol(bioraw)]))
rownames(biodata) <- NULL
names(biodata) <- c("Year", "CPR_Su", "NCP_Su", "SCP_Su", "BioTrn", "ICH_Wi", "CHNjuv", "COHjuv")
print(head(biodata))
```

Select predictors. Change sign of NPGO, NPI & UWI so they correlate positively with other varialbles.

```{r SelectPredictors}
predictors <- envdata # Whole data set
## reverse sign on some predictors to have consistent +/- regr. slopes
predictors[ , grep('NPG_', colnames(predictors))] <- 
  - predictors[ , grep('NPG_', colnames(predictors))]
predictors[ , grep('NPI_', colnames(predictors))] <- 
  - predictors[ , grep('NPI_', colnames(predictors))]
predictors[ , grep('UWI_', colnames(predictors))] <- 
  - predictors[ , grep('UWI_', colnames(predictors))]
plot.names <- colnames(predictors)   # FUTURE: Pretty names
## Testing - subset of predictors 
## predictors <- predictors[ , 1:12]
```

## Analysis

### Some function definitions

First, a function to compute the leave-one-out cv skill score for a bivariate linear model, defined as:
$$
1 - \frac { (n-1) \sum (\hat Y_{(i)} - Y_i)^2 } { (n-2) \sum (\bar Y - Y_i)^2}
$$
where the sums are over the $n$ data points and $\hat Y_{(i)}$ is the predicted value of $Y_i$ from the model with point $i$ left out.

Crude, but effective. Should be able to do this more efficiently for a linear model.

```{r LOOFunc}
loo.skill <- compiler::cmpfun(function(df) {
  # Leave-one-out cross-validation, scaled to skill score, for a 
  #   bivariate linear regr.
  # df is a dataframe with two columns: X & Y
  ybar <- mean(df$Y)
  n <- nrow(df)
  loo.pred <- function(i) predict(lm(Y ~ X, data=df[-i,]), newdata=df[i,])
  .pred <- sapply(1:n, loo.pred)
  loo.cvs <- 1 - (n-1) / (n-2) * sum((.pred - df$Y)^2) / sum((ybar - df$Y)^2)
  return(list(CVS=loo.cvs, X=df$X, Y=df$Y, Pred=.pred))
}) # loo.skill
```

```{r TestLOO, echo=FALSE, eval=FALSE}
testN <- 10
# Perfect relationship:
X <- Y <- rnorm(testN)
tdf <- data.frame(X=X,Y=Y)
res <-loo.skill(tdf)  
print(res$CVS) # should be 1.0
# No relationship:
tdf$Y <- rnorm(testN)
res <-loo.skill(tdf)  
print(res$CVS) # should be near 0.0 for large testN
plot(res$X, res$Y, xlab="X", ylab="Y")
points(res$X, res$Pred, pch='+', col='blue')
# 50% relationship, multiple trials:
res <- c()
for (k in 1:25) {
  tdf$Y <- tdf$X + rnorm(testN) # independent error 
  res <- c(res, loo.skill(tdf)$CVS) # should be near 0.5 for large testN
  }
summary(res)
rm(X, Y, tdf, res)
```

Next, a function to compute the model fit at all scales. For a multivariate data time series of length N, applies a goodness-of-fit function to all overlapping subseries of length n, where n runs from a lower limit k (10 by default) to the entire series length. Results are stored in an N x (N-k+1) matrix suitable for plotting via ``image``.

```{r tsapplyFunc}
tsapply <- compiler::cmpfun(function(dataser, goffnc, minlen=10) {
  # dataser is a multivariate time series, in the form of a data.frame
  # goffnc is a function that fits a model to a data frame, and returns 
  #   a single numeric goodness-of-fit measure.
  # minlen is the minumum data subset length
  N <- nrow(dataser)
  res <- data.frame(time=NULL, scale=NULL, gof=NULL)
  for (n in minlen:N) {
    for (j in 1:(N-n+1)) {
      .sub <- j + 0:(n-1)
      if (length(.sub) != n) stop("length(.sub) = ", length(.sub), ", n = ", n)
      .dat <- dataser[.sub, ]
      res <- rbind(res, data.frame(time=max(.sub), scale=n, gof=goffnc(.dat)))
    } # for(t)
  } # for(n)
  return(res)
}) # tsapply
```

We want a graphic that shows both the strength of the relationship (skill) and its direction (sign of the slope), so define a "signed skill" metric by truncating the skill measure to be non-negative (negative skill means really bad relationship anyway), then multiplying by the sign of the regression slope. Also make a function to plot the resulting metric as a function of time and scale.

In the plot, color indicates sign (blue positive, red negative) and circle size indicates skill. Contours are added at skill levels 0.25 (thin dotted), 0.5 (dashed) and 0.75 (solid).

```{r slopeSkill, fig.height=9, fig.width=9}
slpSkill <- function(X, Y) {
  #return LOO skill and regression slope in one data frame
  loo.res <- tsapply(data.frame(X=X,Y=Y), function(df) {loo.skill(df)$CVS})
  # get regression slopes for color-coding graph
  slp.res <- tsapply(data.frame(X=X,Y=Y), function(df) {
    coefficients(lm(Y ~ X, data=df))['X'] })
  loo.res$slp <- slp.res$gof
  return(loo.res)
} # slpSkill()

skillPlot <- function(ss, title="", dot.scale=0.5) {
  # Plot signed skill on scale v time axis
  ss <- ss[!is.na(ss$gof), ]      # remove na's for interp()
  ss$gof <- pmax(0,ss$gof) # get rid of negative values (very bad fit)
  plot(ss$time, ss$scale, type='n', asp=1.0, xaxs='r', 
       xlab='Interval Endpoint', ylab='Interval Length')
  text(min(ss$time), max(ss$scale), title, cex=1.25, adj=c(0, 1), col='black')
  text(min(ss$time), max(ss$scale) - 0.1 * diff(range(ss$scale)),
       paste0("Long-term Skill: ", round(ss$gof[ss$scale==max(ss$scale)],2)), 
       cex=1, adj=c(0,1), col='black')
  text(min(ss$time), max(ss$scale) - 0.17 * diff(range(ss$scale)),
       paste0("Maximum Skill: ", round(max(ss$gof),2)), 
       cex=1, adj=c(0,1), col='black')
  symbols(ss$time, ss$scale,
            circles=dot.scale * sqrt(ss$gof), inches=FALSE, fg='grey80',
            bg=ifelse(ss$slp<0,"#D34364","#4364D3"), add=T)
  zz <- with(ss, akima::interp(time, scale, gof, xo=sort(unique(time)), 
                               yo=sort(unique(scale))))
  contour(zz, levels=c(0.25, 0.5, 0.75), 
          lty=c(3, 2, 1), lwd=c(1, 2, 2), col='black', 
          drawlabels=FALSE, add=TRUE)
} # skillPlot()
X <- rnorm(30)
Y <- X + rnorm(30)
tst <- slpSkill(X, Y)
skillPlot(tst, title='Test')
rm(X, Y, tst)
```

### Test with AR(1) random series

Generate 12 pairs of random AR(1) series, plot patterns.

```{r ARtest, fig.height=6, fig.width=9}
op <- par(mfrow=c(3,4), mar=c(2,2,1,1), mgp=c(3,0.5,0), fg='grey', tck=1)
for (i in 1:12) {
  X <- arima.sim(n=30, model=list(ar=0.7))
  Y <- arima.sim(n=30, model=list(ar=0.7))
  tst <- slpSkill(X, Y)
  skillPlot(tst, title=paste0('Tst_AR1_',i))
  rm(X, Y, tst)
}
par(op)
```

## Real Data

Compute skill and sign of relationship for all years and scales across selected predictors. (Only run if resulting output doesn't already exist, so to refresh results, delete ``ss.out`` before running.)

```{r AnalLoop}
if (!exists("ss.out")) {
  library(parallel)
  mc <- floor(detectCores()/2)
  preds <- as.list(names(predictors))
  names(preds) <- names(predictors)   # so result is a named list
  ss.out <- mclapply(preds, 
                     function (k) {
                       slpSkill(X=popdata$logAD, Y=predictors[ , k])
                       },
                     mc.cores=mc)
  rm(mc, preds)
} # if (!exists(ss.out))
```

Summarize results and plot. Plots are done only for those with skill above a threshold. The X-axis is the year of ocean entry (return year - 1).

```{r Results, fig.height=6, fig.width=9}
skillthresh <- 0.00
op <- par(mfrow=c(3,4), mar=c(2,2,1,1), mgp=c(3,0.5,0), fg='grey', tck=1)
for (series in names(ss.out)) {
  cat('Predictor: ', series, '\n')
  ss <- ss.out[[series]]
  ss$time <- popdata$YEAR[ss$time]
  cat('\t Range of Skill: ', round(range(ss$gof, na.rm=TRUE),2), '\n')
##  if (max(ss$gof, na.rm=TRUE) > skillthresh) { 
    skillPlot(ss, title=series, dot.scale=1.0) 
##  } # if
} # for(series)
par(op)
rm(skillthresh, op)
```

Look at some clustering patterns in the raw data and in the patterns of skill.

```{r Clustering1, fig.height=9, fig.width=9}
# raw Data
library(MASS)
palette(c("gray40",RColorBrewer::brewer.pal(7,"Dark2")))
dat <- as.matrix(cbind(RECR=popdata$logAD, predictors))
dat <- dat[ !apply(dat, 1, function(x) any(is.na(x))), ]
image(cor(dat), col=RColorBrewer::brewer.pal(11,'RdBu'))
d1 <- as.dist(1 - abs(cor(dat)))             # correlation-based distances
h1 <- hclust(d1, method="single")
clcode <- cutree(h1, 8)
plot(h1, cex=0.5)
data.mds <- cmdscale(d1, k=2)
eqscplot(data.mds, type='n')
text(data.mds, labels=rownames(data.mds), cex=0.5, col=clcode)
rm(dat, d1, h1, clcode, data.mds)
```

```{r Clustering2, fig.height=9, fig.width=9}
# cluster based on similarity of skill patterns
dat <- as.data.frame(lapply(ss.out, "[[", "gof"))
dat <- dat[, -grep("YEAR",colnames(dat))]
dat[dat<0] <- 0
d2 <- dist(t(dat))
h2 <- hclust(d2, method="single")
plot(h2, cex=0.5)
clcode <- cutree(h2, 6)
data.mds <- cmdscale(d2, k=2)
eqscplot(data.mds, type='n')
text(data.mds, labels=rownames(data.mds), cex=0.5, col=clcode)
rm(dat, d2, h2, clcode, data.mds)
```

```{r cleanup, echo=FALSE}
ls() # see what's being saved
save.image() # save data for re-use
```
