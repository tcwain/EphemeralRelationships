---
title: "Ephemeral Relationships Project"
author: "Tom Wainwright, NOAA Northwest Fisheries Science Center"
date: 'Updated: `r Sys.Date()`'
output:
  html_document:
    fig_caption: yes
    highlight: tango
    self_contained: yes
    theme: journal
  pdf_document:
    fig_caption: yes
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.height=4, fig.width=6)
load(".RData") #not done automatically in interactive knitr session.
```

## Introduction

**NOTE:** This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

## Data

Read in the data. Eliminate MEI series from the environmental data, as that almost duplicates ONI, but correlates more with other variables.

```{r ReadData, fig.cap="Oregon Coho Salmon trend"}
dataDir <- file.path(".", "Data")
popdata <- read.table(file.path(dataDir, "OCN_Rivers.dat"), header=TRUE)
popdata$logAD <- log(popdata$ADULTS)  # log-tranformed adults
# Shift popdata so year is ocean-entry year (return year -1)
popdata$YEAR <- popdata$YEAR - 1
# Filter out missing values
popdata <- popdata[!is.na(popdata$ADULTS), ]
envdata <- read.table(file.path(dataDir, "Physical_3mo.dat"), header=TRUE)
envdata <- envdata[, -grep('MEI_', colnames(envdata))]
# Make sure both cover same set of years:
envdata <- envdata[envdata$YEAR %in% popdata$YEAR, ]
popdata <- popdata[popdata$YEAR %in% envdata$YEAR, ]
##summary(popdata)
plot(popdata$YEAR, popdata$ADULTS, type='l', fg='grey', col='blue', 
     lwd=2, log='y',      xlab='Year', ylab='Abundance (1000\`s)', 
     main= 'OCNR Coho Adult Recruits')
##summary(envdata)
```

Select predictors

```{r SelectPredictors}
# FUTURE: Select data here
predictors <- envdata # Whole data set
## Testing - just use 6 predictors 
# predictors <- envdata[ , 1:6]
plot.names <- colnames(predictors)   # FUTURE: Pretty names
npred <- ncol(predictors) #No. of predictor series
```

## Analysis

### Some function definitions

First, a function to compute the leave-one-out cv skill score for a bivariate linear model, defined as:
$$
1 - \frac { (n-1) \sum (\hat Y_{(i)} - Y_i)^2 } { (n-2) \sum (\bar Y - Y_i)^2}
$$
where the sums are over the $n$ data points and $\hat Y_{(i)}$ is the predicted value of $Y_i$ from the model with point $i$ left out.

Crude, but effective. Should be able to do this more efficiently for a linear model.

```{r LOOFunc}
loo.skill <- compiler::cmpfun(function(df) {
  # Leave-one-out cross-validation, scaled to skill score, for a 
  #   bivariate linear regr.
  # df is a dataframe with two columns: X & Y
  ybar <- mean(df$Y)
  n <- nrow(df)
  loo.pred <- function(i) predict(lm(Y ~ X, data=df[-i,]), newdata=df[i,])
  .pred <- sapply(1:n, loo.pred)
  loo.cvs <- 1 - (n-1) / (n-2) * sum((.pred - df$Y)^2) / sum((ybar - df$Y)^2)
  return(list(CVS=loo.cvs, X=df$X, Y=df$Y, Pred=.pred))
}) # loo.skill
```

```{r TestLOO, echo=FALSE, eval=FALSE, fig.cap="Test with no correlation. Circles are data, '+' are loo predictions."}
testN <- 10
# Perfect relationship:
X <- Y <- rnorm(testN)
tdf <- data.frame(X=X,Y=Y)
res <-loo.skill(tdf)  
print(res$CVS) # should be 1.0
# No relationship:
tdf$Y <- rnorm(testN)
res <-loo.skill(tdf)  
print(res$CVS) # should be near 0.0 for large testN
plot(res$X, res$Y, xlab="X", ylab="Y")
points(res$X, res$Pred, pch='+', col='blue')
# 50% relationship, multiple trials:
res <- c()
for (k in 1:25) {
  tdf$Y <- tdf$X + rnorm(testN) # independent error 
  res <- c(res, loo.skill(tdf)$CVS) # should be near 0.5 for large testN
  }
summary(res)
rm(X, Y, tdf, res)
```

Next, a function to compute the model fit at all scales. For a multivariate data time series of length N, applies a goodness-of-fit function to all overlapping subseries of length n, where n runs from a lower limit k (5 by default) to the entire series length. Results are stored in an N x (N-k+1) matrix suitable for plotting via ``image``.

```{r tsapplyFunc}
tsapply <- compiler::cmpfun(function(dataser, goffnc, minlen=5) {
  # dataser is a multivariate time series, in the form of a data.frame
  # goffnc is a function that fits a model to a data frame, and returns 
  #   a single numeric goodness-of-fit measure.
  # minlen is the minumum data subset length
  N <- nrow(dataser)
##  res <- matrix (NA, nrow=N, ncol=N-minlen+1)
  res <- data.frame(time=NULL, scale=NULL, gof=NULL)
#  if ( ! (minlen %% 2) ) minlen <- minlen + 1  #Force minlen to be odd
#  for (n in seq(minlen, N, 2)) { # Only odd values
  for (n in minlen:N) {
    for (j in 1:(N-n+1)) {
      .sub <- j + 0:(n-1)
      if (length(.sub) != n) stop("length(.sub) = ", length(.sub), ", n = ", n)
      .dat <- dataser[.sub, ]
##      res[j+ceiling(n/2)-1, n-minlen] <- goffnc(.dat) #use lower num for n even
      res <- rbind(res, data.frame(time=max(.sub), scale=n, gof=goffnc(.dat)))
    } # for(t)
  } # for(n)
##  return(list(x=0:N, y=minlen:(N+1)-0.5, z=res))
  return(res)
}) # tsapply
```

We want a graphic that shows both the strength of the relationship (skill) and its direction (sign of the slope), so define a "signed skill" metric by truncating the skill measure to be non-negative (negative skill means really bad relationship anyway), then multiplying by the sign of the regression slope. Also make a function to plot the resulting metric as a function of time and scale.

In the plot, color indicates sign (blue positive, red negative) and circle size indicates skill. Contours are added at skill levels 0.25 (thin dotted), 0.5 (dashed) and 0.75 (solid).

```{r slopeSkill, fig.height=6, fig.cap="Test 1"}
slpSkill <- function(X, Y) {
  #return LOO skill and regression slope in one data frame
  loo.res <- tsapply(data.frame(X=X,Y=Y), function(df) {loo.skill(df)$CVS})
  # get regression slopes for color-coding graph
  slp.res <- tsapply(data.frame(X=X,Y=Y), function(df) {
    coefficients(lm(Y ~ X, data=df))['X'] })
  loo.res$slp <- slp.res$gof
  return(loo.res)
} # slpSkill()

skillPlot <- function(ss, title="", dot.scale=0.5) {
  # Plot signed skill on scale v time axis
  ss <- ss[!is.na(ss$gof), ]      # remove na's for interp()
  ss$gof <- pmax(0,ss$gof) # get rid of negative values (very bad fit)
  plot(ss$time, ss$scale, type='n', asp=1.0, xaxs='r', 
       xlab='Interval Endpoint', ylab='Interval Length')
  text(min(ss$time), max(ss$scale), title, cex=2, adj=c(0, 1), col='black')
  text(min(ss$time), max(ss$scale) - 0.1 * diff(range(ss$scale)),
       paste0("Long-term Skill: ", round(ss$gof[ss$scale==max(ss$scale)],2)), 
       cex=1, adj=c(0,1), col='black')
  text(min(ss$time), max(ss$scale) - 0.17 * diff(range(ss$scale)),
       paste0("Maximum Skill: ", round(max(ss$gof),2)), 
       cex=1, adj=c(0,1), col='black')
  symbols(ss$time, ss$scale,
            circles=dot.scale * sqrt(ss$gof), inches=FALSE, fg='grey80',
            bg=ifelse(ss$slp<0,"#D34364","#4364D3"), add=T)
  zz <- with(ss, akima::interp(time, scale, gof, xo=sort(unique(time)), 
                               yo=sort(unique(scale))))
  contour(zz, levels=c(0.25, 0.5, 0.75), 
          lty=c(3, 2, 1), lwd=c(1, 2, 2), col='black', 
          drawlabels=FALSE, add=TRUE)
} # skillPlot()
X <- rnorm(30)
Y <- X + rnorm(30)
tst <- slpSkill(X, Y)
skillPlot(tst, title='Test')
rm(X, Y, tst)
```

## Real Data

Compute skill and sign of relationship for all years and scales across selected predictors. (Only run if resulting output doesn't already exist, so to refresh results, delete ``ss.out`` before running.)

```{r AnalLoop}
if (!exists("ss.out")) {
  library(parallel)
  mc <- floor(detectCores()/2)
  preds <- as.list(names(predictors))
  names(preds) <- names(predictors)   # so result is a named list
  ss.out <- mclapply(preds, 
                     function (k) {
                       slpSkill(X=popdata$logAD, Y=predictors[ , k])
                       },
                     mc.cores=mc)
} # if (!exists(ss.out))
```

Summarize results and plot. Plots are done only for those with skill above a threshold. The X-axis is the year of ocean entry (return year - 1).

```{r Results, fig.height=3, fig.width=9, fig.cap="Coho V Environment"}
skillthresh <- 0.25
op <- par(mfrow=c(1,3), mar=c(2,2,1,1), mgp=c(3,0.5,0), fg='grey', tck=1)
for (series in names(ss.out)) {
  cat('Predictor: ', series, '\n')
  ss <- ss.out[[series]]
  ss$time <- popdata$YEAR[ss$time]
  cat('\t Range of Skill: ', round(range(ss$gof),2), '\n')
  if (max(ss$gof, na.rm=TRUE) > skillthresh) { 
    skillPlot(ss, title=series, dot.scale=1.0) 
  } # if
} # for(series)
par(op)
rm(op)
```

Look at some clustering patterns in the raw data and in the patterns of skill.

```{r Clustering1, fig.height=9, fig.width=9}
# raw Data, leave out YEAR (col. 1) from predictors
library(MASS)
dat <- as.matrix(cbind(RECR=popdata$logAD, predictors[, -1]))
print(colnames(dat))
image(cor(dat), col=RColorBrewer::brewer.pal(11,'RdBu'))
d1 <- as.dist(1 - abs(cor(dat)))             # correlation-based distances
h1 <- hclust(d1, method="single")
clcode <- cutree(h1, 7)
plot(h1, cex=0.5)
data.mds <- cmdscale(d1, k=2)
eqscplot(data.mds, type='n')
text(data.mds, labels=rownames(data.mds), cex=0.5, col=clcode)
```

Bonneville flow and NPGO are strongly clustered outliers, NPI is all over the place, ONI clusters together (but not in the mds plot), not much else of interest. The MDS plot seems to need more axes to capture the structure.

```{r Clustering2, fig.height=9, fig.width=9}
# cluster based on similarity of skill patterns
dat <- as.data.frame(lapply(ss.out, "[[", "gof"))
dat <- dat[, -grep("YEAR",colnames(dat))]
dat[dat<0] <- 0
d2 <- dist(t(dat))
h2 <- hclust(d2, method="single")
plot(h2, cex=0.5)
clcode <- cutree(h2, 7)
data.mds <- cmdscale(d2, k=2)
eqscplot(data.mds, type='n')
text(data.mds, labels=rownames(data.mds), cex=0.5, col=clcode)
```

Not much of interest there. BFL still mostly outliers, more seasonal separations, little interpretable structure otherwise.

```{r cleanup, echo=FALSE}
save.image() # save data for re-use
```
